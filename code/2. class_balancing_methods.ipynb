{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec16b495",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7ec17ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creadint directory to store evaluation metrics for each methods\n",
    "evaluation_files_loc = '../files/class_balancing_methods_evaluations/'\n",
    "if not os.path.exists(evaluation_files_loc):\n",
    "    os.mkdir(evaluation_files_loc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd69235",
   "metadata": {},
   "source": [
    "### Reading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3071f4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File location of the dataset\n",
    "data_loc = \"./Churn_Modelling.csv\"\n",
    "\n",
    "# Read the CSV file into a Pandas DataFrame, using the first column as the index\n",
    "df = pd.read_csv(data_loc, index_col=0)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f6003f5",
   "metadata": {},
   "source": [
    "### Drop all categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ada866d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['CustomerId', 'Surname','Geography', 'Gender'], axis = 1,inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d8bcf59",
   "metadata": {},
   "source": [
    "## Functions for model training and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b3e1b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def features_target_split(df, target_col='Exited'):\n",
    "    \"\"\"\n",
    "    Split the DataFrame into features and target variables.\n",
    "    \n",
    "    Parameters:\n",
    "        df (DataFrame): The input DataFrame.\n",
    "        target_col (str): The name of the target column. Default is 'Exited'.\n",
    "        \n",
    "    Returns:\n",
    "        x (DataFrame): The features.\n",
    "        y (Series): The target variable.\n",
    "    \"\"\"\n",
    "    # Drop the target column from the DataFrame to get the features\n",
    "    x = df.drop(target_col, axis=1)\n",
    "    \n",
    "    # Assign the target column as the y variable\n",
    "    y = df[target_col]\n",
    "    \n",
    "    # Return the features and target variables\n",
    "    return x,y\n",
    "\n",
    "def train_test_split(x,y,df,target_col='Exited', test_size=0.2, random_state=42):\n",
    "    \"\"\"\n",
    "    Split the features and target variables into training and testing sets.\n",
    "    \n",
    "    Parameters:\n",
    "        x (DataFrame): The features.\n",
    "        y (Series): The target variable.\n",
    "        df (DataFrame): The original DataFrame.\n",
    "        target_col (str): The name of the target column. Default is 'Exited'.\n",
    "        test_size (float or int): The proportion or absolute number of samples to include in the testing set. Default is 0.2.\n",
    "        random_state (int): The seed used by the random number generator. Default is 42.\n",
    "        \n",
    "    Returns:\n",
    "        x_train (DataFrame): The training set features.\n",
    "        x_test (DataFrame): The testing set features.\n",
    "        y_train (Series): The training set target variable.\n",
    "        y_test (Series): The testing set target variable.\n",
    "    \"\"\"\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    \n",
    "    # Split the features and target variables into training and testing sets\n",
    "    # Stratified is being used to maintain the proportion of class [0 and 1] in splits.\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, \n",
    "                                                        test_size=test_size, \n",
    "                                                        random_state=random_state, \n",
    "                                                        stratify=df[target_col])\n",
    "    \n",
    "    return x_train, x_test, y_train, y_test\n",
    "\n",
    "def logistic_model_train(x_train, y_train, random_state=42, max_iter=1000):\n",
    "    \"\"\"\n",
    "    Train a logistic regression model using the provided training data.\n",
    "    \n",
    "    Parameters:\n",
    "        x_train (DataFrame): The training set features.\n",
    "        y_train (Series): The training set target variable.\n",
    "        random_state (int): The seed used by the random number generator. Default is 42.\n",
    "        max_iter (int): The maximum number of iterations for the solver to converge. Default is 1000.\n",
    "        \n",
    "    Returns:\n",
    "        log_reg_model (LogisticRegression): The trained logistic regression model.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create an instance of LogisticRegression model with specified random_state and max_iter\n",
    "    log_reg_model = LogisticRegression(random_state=random_state, max_iter=max_iter)\n",
    "    \n",
    "    # Fit the logistic regression model to the training data\n",
    "    log_reg_model.fit(x_train, y_train)\n",
    "    \n",
    "    return log_reg_model\n",
    "\n",
    "def prediction(log_reg_model, x_train, x_test):\n",
    "    \"\"\"\n",
    "    Generate predictions using a trained logistic regression model.\n",
    "    \n",
    "    Parameters:\n",
    "        log_reg_model (LogisticRegression): The trained logistic regression model.\n",
    "        x_train (array-like or sparse matrix): The training set features.\n",
    "        x_test (array-like or sparse matrix): The testing set features.\n",
    "        \n",
    "    Returns:\n",
    "        y_pred_train (array-like): Predicted labels for the training set.\n",
    "        y_pred_test (array-like): Predicted labels for the testing set.\n",
    "        y_pred_test_proba (array-like): Predicted probabilities for the testing set.\n",
    "    \"\"\"\n",
    "    # Generate predictions for the training set\n",
    "    y_pred_train = log_reg_model.predict(x_train)\n",
    "    \n",
    "    # Generate predictions for the testing set\n",
    "    y_pred_test = log_reg_model.predict(x_test)\n",
    "    \n",
    "    # Generate predicted probabilities for the testing set\n",
    "    y_pred_test_proba = log_reg_model.predict_proba(x_test)\n",
    "    \n",
    "    return y_pred_train, y_pred_test, y_pred_test_proba\n",
    "\n",
    "class Evaluation():\n",
    "    def __init__(self,y_train, y_test, y_pred_train, y_pred_test, y_pred_test_proba):\n",
    "        self.y_train = y_train\n",
    "        self.y_test = y_test\n",
    "        self.y_pred_train = y_pred_train\n",
    "        self.y_pred_test = y_pred_test\n",
    "        self.y_pred_test_proba = y_pred_test_proba\n",
    "        \n",
    "    def __ks_stats_value__(self):\n",
    "        \"\"\"\n",
    "        Calculate the Kolmogorov-Smirnov (KS) statistic and p-value.\n",
    "        \n",
    "        Returns:\n",
    "            ks_stat (float): The KS statistic.\n",
    "            p_value (float): The p-value.\n",
    "        \"\"\"\n",
    "        \n",
    "        # proba_non_churn contains the predicted probabilities for instances that did not churn\n",
    "        proba_non_churn = self.y_pred_test_proba[:,1][self.y_test==0]\n",
    "        \n",
    "        # proba_churn contains the predicted probabilities for instances that actually churned\n",
    "        proba_churn = self.y_pred_test_proba[:,1][self.y_test==1]\n",
    "        \n",
    "        # Calculating Kolmogorov-Smirnov (KS) statistic and p-value\n",
    "        ks_stat, p_value = ks_2samp(proba_non_churn, proba_churn)\n",
    "        return ks_stat, p_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5abaecc0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
